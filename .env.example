# ============================================================================
# Deep-Tutor Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your API keys and settings.
# All API keys should be kept confidential and never committed to version control.
# You can adjust the max_token parameters in DeepTutor/config/agents.yaml.
# ============================================================================

# ============================================================================
# Server Configuration
# ============================================================================
# Configure the server ports and API URL for remote access.

# Backend API port (default: 8001)
# BACKEND_PORT=8001

# Frontend web port (default: 3782)
# FRONTEND_PORT=3782

# Frontend API Base URL (for remote/LAN access)
# Set this when accessing DeepTutor from another device on your network.
# Example: If your server IP is 192.168.1.100, set:
#   NEXT_PUBLIC_API_BASE=http://192.168.1.100:8001
# If not set, defaults to http://localhost:8001 (only works on the local machine)

# NEXT_PUBLIC_API_BASE=http://your-server-ip:8001 (optional)

# ============================================================================
# LLM Deployment Mode Configuration
# ============================================================================
# Control how DeepTutor selects LLM providers.
#
# Options:
#   - hybrid (default): Use both API and Local providers. Active provider takes priority.
#   - api: Only use cloud API providers (OpenAI, Anthropic, DeepSeek, etc.)
#   - local: Only use local/self-hosted providers (Ollama, LM Studio, vLLM, etc.)
#
# In hybrid mode, you can add both API and local providers via the Settings UI,
# and switch between them by setting one as "active".

LLM_MODE=hybrid

# ============================================================================
# LLM (Large Language Model) Configuration
# ============================================================================
# Configure the main AI model used for reasoning, generation, and conversation.
# Supports OpenAI-compatible APIs (OpenAI, Azure OpenAI, DeepSeek, Qwen, etc.)
# and local servers (Ollama, LM Studio, vLLM, llama.cpp).
#
# Note: These environment variables serve as the default/fallback configuration.
# You can also add providers via the Settings UI, which takes priority when active.

# LLM service provider type
# Options: openai, azure_openai, ollama, anthropic
LLM_BINDING=openai

# Model name for the LLM
# Cloud examples: gpt-4o, gpt-4o-mini, deepseek-chat, claude-3-5-sonnet-20241022
# Local examples: llama3.2, qwen2.5, mistral-nemo, deepseek-r1
LLM_MODEL=

# LLM API endpoint URL
# Cloud examples:
#   - OpenAI: https://api.openai.com/v1
#   - Azure OpenAI: https://{your-resource}.openai.azure.com/openai/deployments/{deployment-id}
#     (Note: For Azure, you must include the full deployment path, not just the base URL)
# Local examples:
#   - Ollama: http://localhost:11434/v1
#   - LM Studio: http://localhost:1234/v1
#   - vLLM: http://localhost:8000/v1
#   - llama.cpp: http://localhost:8080/v1
LLM_HOST=

# LLM API authentication key
# Required for cloud APIs, optional for local deployment
# For Ollama, you can use any string (e.g., "ollama")
LLM_API_KEY=

# API version for Azure OpenAI (e.g., 2024-02-15-preview)
# Required only when LLM_BINDING=azure_openai
LLM_API_VERSION=

# Disable SSL certificate verification (set 'true' for self-signed certificates)
DISABLE_SSL_VERIFY=false

# ============================================================================
# Embedding Model Configuration
# ============================================================================
# Configure the text embedding model used for semantic search and RAG.
# Required for knowledge base functionality.

# Embedding service provider type
# Options: openai, azure_openai, ollama, lollms
EMBEDDING_BINDING=openai

# Embedding model name
# Cloud examples: text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002
# Local examples (Ollama): nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=text-embedding-3-large

# Embedding vector dimension
# text-embedding-3-large: 3072
# text-embedding-3-small: 1536
# nomic-embed-text: 768
# mxbai-embed-large: 1024
EMBEDDING_DIMENSION=3072

# Embedding API endpoint URL
# Cloud examples:
#   - OpenAI: https://api.openai.com/v1
#   - Azure OpenAI: https://{your-resource}.openai.azure.com/openai/deployments/{deployment-id}
#     (Note: For Azure, you must include the full deployment path, not just the base URL)
# Local (Ollama): http://localhost:11434
EMBEDDING_HOST=

# Embedding API authentication key
# Required for cloud providers, not needed for Ollama
EMBEDDING_API_KEY=

# API version for Azure OpenAI (e.g., 2024-02-15-preview)
# Required only when EMBEDDING_BINDING=azure_openai
EMBEDDING_API_VERSION=

# ============================================================================
# TTS (Text-to-Speech) Configuration (Optional)
# ============================================================================
# Configure voice synthesis for the Co-Writer (Interactive IdeaGen) narration feature.
# Also remember to choose a voice in DeepTutor/config/main.yaml.

# TTS model name (e.g., tts-1, tts-1-hd)
TTS_MODEL=

# TTS API endpoint URL
#   - OpenAI: https://api.openai.com/v1
#   - Azure OpenAI: https://{your-resource}.openai.azure.com/
#     (Note: For TTS on Azure, use the base resource URL)
TTS_URL=

# TTS API authentication key
TTS_API_KEY=

# TTS service provider type (openai, azure_openai)
TTS_BINDING=openai

# API version for Azure OpenAI TTS (e.g., 2024-02-15-preview)
# Required only when TTS_BINDING=azure_openai
TTS_BINDING_API_VERSION=

# ============================================================================
# Web Search Configuration
# ============================================================================
# Configure external search APIs for research features.

# Search provider to use for web search
# Options: perplexity, baidu, tavily, exa, serper, jina
# Default: perplexity
SEARCH_PROVIDER=perplexity

# ----------------------------------------------------------------------------
# Perplexity AI Search Configuration
# ----------------------------------------------------------------------------
# Perplexity API key for AI-powered search
# Get your API key at: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=

# ----------------------------------------------------------------------------
# Baidu AI Search Configuration (百度AI搜索)
# ----------------------------------------------------------------------------
# Baidu API Key for intelligent search and generation
# Get your API key at: https://console.bce.baidu.com/ai_apaas/resource
# Format: bce-v3/ALTAK-xxx/xxx or the full API key
BAIDU_API_KEY=

# ----------------------------------------------------------------------------
# Tavily Research Search Configuration
# ----------------------------------------------------------------------------
# Tavily API key for research-focused search
# Get your API key at: https://tavily.com
TAVILY_API_KEY=

# ----------------------------------------------------------------------------
# Exa Neural Search Configuration
# ----------------------------------------------------------------------------
# Exa API key for embeddings-based neural search
# Get your API key at: https://dashboard.exa.ai
EXA_API_KEY=

# ----------------------------------------------------------------------------
# Serper Google SERP Configuration
# ----------------------------------------------------------------------------
# Serper API key for Google search results
# Get your API key at: https://serper.dev
SERPER_API_KEY=

# ----------------------------------------------------------------------------
# Jina Reader Search Configuration
# ----------------------------------------------------------------------------
# Jina API key for SERP with full content extraction
# Get your API key at: https://jina.ai/reader (optional, has free tier)
JINA_API_KEY=

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level for RAG tool module
# Options: DEBUG, INFO, WARNING, ERROR
RAG_TOOL_MODULE_LOG_LEVEL=INFO
